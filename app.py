# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PUUHA6ETsGCSbMTtm7sBNdzWHVhBjHer
"""

import pandas as pd
import numpy as np

df=pd.read_csv('CAR DETAILS.csv')
df.head()



df.duplicated().sum()

df.drop_duplicates(inplace=True)
df.duplicated().sum()

cat_cols=df.dtypes[df.dtypes=='object'].index
num_cols=df.dtypes[df.dtypes!='object'].index
print(cat_cols)
print(num_cols)

df['brand']=df['name'].str.split(expand=True)[0]
df['model']=df['name'].str.split(expand=True)[1]
df.head()

from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()

df['fuel_type'] = lb.fit_transform(df['fuel'])
df['Type_of_Seller'] = lb.fit_transform(df['seller_type'])
df['Transmit'] = lb.fit_transform(df['transmission'])
df['Owner_Type'] = lb.fit_transform(df['owner'])
df['brand_name'] = lb.fit_transform(df['brand'])
df['model_name'] = lb.fit_transform(df['model'])

data = df.drop(['name', 'fuel', 'seller_type', 'transmission', 'owner', 'brand','model'], axis=1)
data.head()

data.to_csv('ds_for_ml.csv')

def treatment_outliers(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]

for i in num_cols:
    data = treatment_outliers(data, i)



from sklearn.model_selection import train_test_split

x = data.drop(columns=['selling_price'])
y = data['selling_price']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=22)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

from sklearn.metrics import *

def eval_model(model,mname):
    model.fit(x_train,y_train)
    ypred = model.predict(x_test)
    train_r2 = model.score(x_train,y_train)
    test_r2 = model.score(x_test,y_test)
    mae = mean_absolute_error(y_test,ypred)
    mse = mean_squared_error(y_test,ypred)
    rmse = np.sqrt(mse)
    res = pd.DataFrame({'Train_R2':train_r2,'Test_R2':test_r2,'MAE':mae,
                       'MSE':mse,'RMSE':rmse},index=[mname])
    return res,ypred

from sklearn.linear_model import *
from sklearn.tree import *
from sklearn.ensemble import *
from sklearn.neighbors import *
from xgboost import XGBRegressor

lr = LinearRegression()
lr_res,ypred_lr = eval_model(lr,'LinReg')
lr_res

dt = DecisionTreeRegressor(max_depth=6,min_samples_split=8)
dt_res,ypred_dt = eval_model(dt,'DT_Reg')
dt_res

knn = KNeighborsRegressor(n_neighbors=11)
knn_res,ypred_knn = eval_model(knn,'KNN_Reg')
knn_res

rf = RandomForestRegressor(n_estimators=80,max_depth=6,min_samples_split=8)
rf_res,ypred_rf = eval_model(rf,'RF_Reg')
rf_res

rg = Ridge()
rg_res,y_pred_rg = eval_model(rg,'Ridge_reg')
rg_res

ls = Lasso()
ls_res,y_pred_rg = eval_model(ls,'Lasso_reg')
ls_res

all_res  = pd.concat([lr_res,dt_res,knn_res,rf_res,rg_res,ls_res])
all_res

import pickle
import joblib

pickle.dump(rf,open('Best_Model_1.pkl','wb'))

load_model=joblib.load('Best_Model_1.pkl')

random_indices = np.random.choice(data.index, size= 20, replace=False)
sample_data_20 = data.loc[random_indices]
sample_data_20

sample_data=sample_data_20.drop('selling_price', axis=1)

Prediction_sample = pd.DataFrame(Sample_pred)
Prediction_sample

Sample_pred = load_model.predict(sample_data)
Sample_pred

sample_data_20['pred_selling_price']=Prediction_sample.values
sample_data_20

com = (sample_data_20[['selling_price', 'pred_selling_price']])
com.to_csv('sample_prediction.csv')
com











